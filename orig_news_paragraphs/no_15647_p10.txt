"When Did White Men Become The Bad Guys in America?" " That may be unfair because women and black Americans weren’t given the opportunity to significantly contribute for most of our nation’s history, but it is true. " 